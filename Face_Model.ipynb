{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D,MaxPooling2D, LeakyReLU, PReLU , Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_tfrecord(tfrecord_file, batch_size, net):\n",
    "    # generate a input queue\n",
    "    # each epoch shuffle\n",
    "    filename_queue = tf.string_input_producer([tfrecord_file],shuffle=True)\n",
    "    # read tfrecord\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    image_features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image/encoded': tf.FixedLenFeature([], tf.string),#one image  one record\n",
    "            'image/label': tf.FixedLenFeature([], tf.int64),\n",
    "            'image/roi': tf.FixedLenFeature([4], tf.float32),\n",
    "            'image/landmark': tf.FixedLenFeature([10],tf.float32)\n",
    "        }\n",
    "    )\n",
    "    if net == 'PNet':\n",
    "        image_size = 12\n",
    "    elif net == 'RNet':\n",
    "        image_size = 24\n",
    "    else:\n",
    "        image_size = 48\n",
    "    image = tf.decode_raw(image_features['image/encoded'], tf.uint8)\n",
    "    image = tf.reshape(image, [image_size, image_size, 3])\n",
    "    image = (tf.cast(image, tf.float32)-127.5) / 128\n",
    "    \n",
    "    # image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(image_features['image/label'], tf.float32)\n",
    "    roi = tf.cast(image_features['image/roi'],tf.float32)\n",
    "    landmark = tf.cast(image_features['image/landmark'],tf.float32)\n",
    "    image, label,roi,landmark = tf.train.batch(\n",
    "        [image, label,roi,landmark],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=2,\n",
    "        capacity=1 * batch_size\n",
    "    )\n",
    "    label = tf.reshape(label, [batch_size])\n",
    "    roi = tf.reshape(roi,[batch_size,4])\n",
    "    landmark = tf.reshape(landmark,[batch_size,10])\n",
    "    return image, label, roi,landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class PNet():\n",
    "    #P-Net\n",
    "\n",
    "\n",
    "    # Data Preprocessing\n",
    "    # before passing your data into a neural network you normalize the data by Scaling it\n",
    "\n",
    "    # scaling the data \n",
    "    #X = X/255.0\n",
    "\n",
    "    #you can also use tf.keras.utils.normalize(X) \n",
    "#     x = layers.Dense(64, activation='relu')(inputs)\n",
    "#     x = layers.Dense(64, activation='relu')(x)\n",
    "#     predictions = layers.Dense(10, activation='softmax')(x)\n",
    "    # Convoluted neural network\n",
    "\n",
    "def p_net():\n",
    "\n",
    "    model = Sequential() #there are 2 types of models but this is the most common\n",
    "    model.add(Conv2D(10,(3, 3), strides=1, name='conv1',padding='SAME', input_shape =(12, 12, 3) ) )\n",
    "    model.add(PReLU(name='prelu1'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(16,(3, 3), strides=1,name='conv2', input_shape =(5, 5, 10)))\n",
    "    model.add(PReLU(name='prelu2'))\n",
    "\n",
    "    model.add(Conv2D(32,(3,3),strides=1,name='conv3'))\n",
    "    model.add(PReLU(name='prelu3'))\n",
    "\n",
    "    model.add(Conv2D(2, (1, 1), activation='softmax',name='classifier1'))\n",
    "    model.add(PReLU(name='prelu4'))\n",
    "\n",
    "    model.add(Dense(4,name='bbox_regression'))\n",
    "\n",
    "    model.add(Dense(10,name='landmark'))\n",
    "\n",
    "    #model = tf.keras.Model(inputs=, outputs=)\n",
    "    model.compile(optimizer=tf.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    #my_adam = adam(lr = 0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#R-Net\n",
    "\n",
    "def r_net():\n",
    "    model = Sequential() #there are 2 types of models but this is the most common\n",
    "    model.add(Conv2D(28, (3, 3), strides=1, name='conv1', input_shape =(24, 24, 3)))\n",
    "    model.add(PReLU(name='prelu1'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(48, (3, 3), strides=1, name='conv2'))\n",
    "    model.add(PReLU(name='prelu2'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (2, 2), strides=1, name='conv3'))\n",
    "    model.add(PReLU(name='prelu3'))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(PReLU(name='prelu4'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.add(Dense(4))#THere is something being used input_layer_name='prelu4)\n",
    "\n",
    "#O-Net\n",
    "\n",
    "def o_net():\n",
    "    model = Sequential() #there are 2 types of models but this is the most common\n",
    "    model.add(Conv2D(32, (3, 3), strides=1, name='conv1'), input_shape =(48, 48, 3))\n",
    "    model.add(PReLU(name='prelu1'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides=1, name='conv2'))\n",
    "    model.add(PReLU(name='prelu2'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides=1, name='conv3'))\n",
    "    model.add(PReLU(name='prelu3'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(128, (2, 2), strides=1, name='conv4'))\n",
    "    model.add(PReLU(name='prelu4'))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(PReLU(name='prelu5'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.add(Dense(4))#THere is something being used input_layer_name='prelu5\n",
    "\n",
    "    model.add(Dense(10))#THere is something being used input_layer_name='prelu5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = PNet\n",
    "# batch_size = 32\n",
    "\n",
    "\n",
    "# def read_single_tfrecord(tfrecord_file, batch_size, net):\n",
    "#     # generate a input queue\n",
    "#     # each epoch shuffle\n",
    "#     filename_queue = tf.string_input_producer([tfrecord_file],shuffle=True)\n",
    "#     # read tfrecord\n",
    "#     reader = tf.TFRecordReader()\n",
    "#     _, serialized_example = reader.read(filename_queue)\n",
    "#     image_features = tf.parse_single_example(\n",
    "#         serialized_example,\n",
    "#         features={\n",
    "#             'image/encoded': tf.FixedLenFeature([], tf.string),#one image  one record\n",
    "#             'image/label': tf.FixedLenFeature([], tf.int64),\n",
    "#             'image/roi': tf.FixedLenFeature([4], tf.float32),\n",
    "#             'image/landmark': tf.FixedLenFeature([10],tf.float32)\n",
    "#         }\n",
    "#     )\n",
    "#     if net == 'PNet':\n",
    "#         image_size = 12\n",
    "#     elif net == 'RNet':\n",
    "#         image_size = 24\n",
    "#     else:\n",
    "#         image_size = 48\n",
    "#     image = tf.decode_raw(image_features['image/encoded'], tf.uint8)\n",
    "#     image = tf.reshape(image, [image_size, image_size, 3])\n",
    "#     image = (tf.cast(image, tf.float32)-127.5) / 128\n",
    "    \n",
    "#     # image = tf.image.per_image_standardization(image)\n",
    "#     label = tf.cast(image_features['image/label'], tf.float32)\n",
    "#     roi = tf.cast(image_features['image/roi'],tf.float32)\n",
    "#     landmark = tf.cast(image_features['image/landmark'],tf.float32)\n",
    "#     image, label,roi,landmark = tf.train.batch(\n",
    "#         [image, label,roi,landmark],\n",
    "#         batch_size=batch_size,\n",
    "#         num_threads=2,\n",
    "#         capacity=1 * batch_size\n",
    "#     )\n",
    "#     label = tf.reshape(label, [batch_size])\n",
    "#     roi = tf.reshape(roi,[batch_size,4])\n",
    "#     landmark = tf.reshape(landmark,[batch_size,10])\n",
    "#     return image, label, roi,landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = p_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 12, 12, 10)        280       \n",
      "_________________________________________________________________\n",
      "prelu1 (PReLU)               (None, 12, 12, 10)        1440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 3, 3, 16)          1456      \n",
      "_________________________________________________________________\n",
      "prelu2 (PReLU)               (None, 3, 3, 16)          144       \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 1, 1, 32)          4640      \n",
      "_________________________________________________________________\n",
      "prelu3 (PReLU)               (None, 1, 1, 32)          32        \n",
      "_________________________________________________________________\n",
      "classifier1 (Conv2D)         (None, 1, 1, 2)           66        \n",
      "_________________________________________________________________\n",
      "prelu4 (PReLU)               (None, 1, 1, 2)           2         \n",
      "_________________________________________________________________\n",
      "bbox_regression (Dense)      (None, 1, 1, 4)           12        \n",
      "_________________________________________________________________\n",
      "landmark (Dense)             (None, 1, 1, 10)          50        \n",
      "=================================================================\n",
      "Total params: 8,122\n",
      "Trainable params: 8,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your own reader function.\n",
    "image_features = tf.parse_single_example(\n",
    "       serialized_example,\n",
    "       features={\n",
    "           'image/encoded': tf.FixedLenFeature([], tf.string),#one image  one record\n",
    "           'image/label': tf.FixedLenFeature([], tf.int64),\n",
    "           'image/roi': tf.FixedLenFeature([4], tf.float32),\n",
    "           'image/landmark': tf.FixedLenFeature([10],tf.float32)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_record(example):\n",
    "    image_features = tf.io.parse_single_example(\n",
    "       example,\n",
    "       features={\n",
    "           'image/encoded': tf.io.FixedLenFeature([], tf.string),#one image  one record\n",
    "           'image/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "           'image/roi': tf.io.FixedLenFeature([4], tf.float32),\n",
    "           'image/landmark': tf.io.FixedLenFeature([10],tf.float32)\n",
    "       }\n",
    "    )\n",
    "    image = tf.io.decode_raw(image_features['image/encoded'], tf.uint8)\n",
    "    image = tf.reshape(image, [12, 12, 3])\n",
    "    image = (tf.cast(image, tf.float32)-127.5) / 128\n",
    "    \n",
    "    # image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(image_features['image/label'], tf.float32)\n",
    "    roi = tf.cast(image_features['image/roi'],tf.float32)\n",
    "    landmark = tf.cast(image_features['image/landmark'],tf.float32)\n",
    "    return image, (label, roi)\n",
    "        \n",
    "\n",
    "    \n",
    "# image, label,roi,landmark = tf.train.batch(\n",
    "#     [image, label,roi,landmark],\n",
    "#     batch_size=batch_size,\n",
    "#     num_threads=2,\n",
    "#     capacity=1 * batch_size\n",
    "# )\n",
    "# label = tf.reshape(label, [batch_size])\n",
    "# roi = tf.reshape(roi,[batch_size,4])\n",
    "# landmark = tf.reshape(landmark,[batch_size,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 384\n",
    "\n",
    "buffer_size=10 * BATCH_SIZE\n",
    "\n",
    "def get_batch(filenames):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "    \n",
    "    \n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    \n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset)\n",
    "    dataset = dataset.map(read_record)\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    \n",
    "    dataset = dataset.prefetch(buffer_size=buffer_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filename = \"C:\\\\Users\\\\F. Oseni\\\\jupyter notebook\\\\MTCNN-Tensorflow-master1\\\\MTCNN-Tensorflow-master1\\\\dta\\\\imglists\\\\PNet\\\\train_PNet_landmark.tfrecord_shuffle\"\n",
    "validation_filename = \"C:\\\\Users\\\\F. Oseni\\\\jupyter notebook\\\\MTCNN-Tensorflow-master1\\\\MTCNN-Tensorflow-master1\\\\dta\\\\imglists\\\\PNet\\\\train_PNet_landmark.tfrecord_shuffle\"\n",
    "def get_training_datest():\n",
    "    return get_batch(training_filename)\n",
    "\n",
    "def get_validation_dataset():\n",
    "    return get_batch(validation_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_net():\n",
    "      \n",
    "        inputs = tf.keras.Input(shape=(12,12,3))\n",
    "\n",
    "        model = tf.keras.layers.Conv2D(10,(3, 3), strides=1, name='conv1',padding='SAME')(inputs)\n",
    "        model = tf.keras.layers.PReLU(name='prelu1')(model)\n",
    "        model = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2))(model)\n",
    "\n",
    "        model = tf.keras.layers.Conv2D(16,(3, 3), strides=1,name='conv2')(model)\n",
    "        model = tf.keras.layers.PReLU(name='prelu2')(model)\n",
    "\n",
    "        model = tf.keras.layers.Conv2D(32,(3,3),strides=1,name='conv3')(model)\n",
    "        model = tf.keras.layers.PReLU(name='prelu3')(model)\n",
    "\n",
    "        classifier1 = tf.keras.layers.Conv2D(2, (1, 1), activation='softmax',name='classifier1')(model)\n",
    "        #I am not sure if this line of code is impoertant\n",
    "        #classifier1 = tf.keras.layers.Reshape((2,))(classifier1)   # this layer has to be deleted in order to enalbe arbitraty shape input\n",
    "\n",
    "        bbox_regress = Conv2D(4, (1, 1),name='bbox1')(model)\n",
    "        #I am not sure if this line of code is impoertant\n",
    "        #bbox_regress = tf.keras.layers.Reshape((4,))(bbox_regress)\n",
    "\n",
    "        #THis last code is not usually included in most mtcnn replicas\n",
    "        #landmark = Conv2D(10, (1, 1),name='landmark1')(model)\n",
    "        #landmark =  tf.keras.layers.Reshape((10,))(landmark)\n",
    "\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=[classifier1,bbox_regress])\n",
    "        model.compile(optimizer=tf.optimizers.Adam(0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsss = p_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 49s 485ms/step - loss: 0.7472 - classifier1_loss: 0.6939 - bbox1_loss: 0.0533 - classifier1_accuracy: 0.3500 - bbox1_accuracy: 0.6603 - val_loss: 0.7487 - val_classifier1_loss: 0.6932 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.7495 - classifier1_loss: 0.6932 - bbox1_loss: 0.0563 - classifier1_accuracy: 0.3500 - bbox1_accuracy: 0.6665 - val_loss: 0.7487 - val_classifier1_loss: 0.6932 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.7482 - classifier1_loss: 0.6932 - bbox1_loss: 0.0550 - classifier1_accuracy: 0.3494 - bbox1_accuracy: 0.6626 - val_loss: 0.7487 - val_classifier1_loss: 0.6932 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.7540 - classifier1_loss: 0.6932 - bbox1_loss: 0.0608 - classifier1_accuracy: 0.3499 - bbox1_accuracy: 0.6576 - val_loss: 0.7487 - val_classifier1_loss: 0.6932 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 0.7470 - classifier1_loss: 0.6932 - bbox1_loss: 0.0538 - classifier1_accuracy: 0.3495 - bbox1_accuracy: 0.6567 - val_loss: 0.7487 - val_classifier1_loss: 0.6931 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.7559 - classifier1_loss: 0.6932 - bbox1_loss: 0.0627 - classifier1_accuracy: 0.3508 - bbox1_accuracy: 0.6600 - val_loss: 0.7487 - val_classifier1_loss: 0.6931 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 0.7536 - classifier1_loss: 0.6931 - bbox1_loss: 0.0605 - classifier1_accuracy: 0.3494 - bbox1_accuracy: 0.6614 - val_loss: 0.7487 - val_classifier1_loss: 0.6931 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.7462 - classifier1_loss: 0.6931 - bbox1_loss: 0.0531 - classifier1_accuracy: 0.3492 - bbox1_accuracy: 0.6575 - val_loss: 0.7487 - val_classifier1_loss: 0.6931 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 0.7551 - classifier1_loss: 0.6931 - bbox1_loss: 0.0620 - classifier1_accuracy: 0.3496 - bbox1_accuracy: 0.6632 - val_loss: 0.7487 - val_classifier1_loss: 0.6931 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.7519 - classifier1_loss: 0.6931 - bbox1_loss: 0.0588 - classifier1_accuracy: 0.3481 - bbox1_accuracy: 0.6615 - val_loss: 0.7487 - val_classifier1_loss: 0.6931 - val_bbox1_loss: 0.0555 - val_classifier1_accuracy: 0.3486 - val_bbox1_accuracy: 0.6578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1da197225c0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsss.fit(get_training_datest(), steps_per_epoch=100, epochs=10, validation_data=get_validation_dataset(), validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 12, 12, 10)   280         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prelu1 (PReLU)                  (None, 12, 12, 10)   1440        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 5, 5, 10)     0           prelu1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 3, 3, 16)     1456        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prelu2 (PReLU)                  (None, 3, 3, 16)     144         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 1, 1, 32)     4640        prelu2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prelu3 (PReLU)                  (None, 1, 1, 32)     32          conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "classifier1 (Conv2D)            (None, 1, 1, 2)      66          prelu3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bbox1 (Conv2D)                  (None, 1, 1, 4)      132         prelu3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "landmark1 (Conv2D)              (None, 1, 1, 10)     330         prelu3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 2)            0           classifier1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 4)            0           bbox1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10)           0           landmark1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,520\n",
      "Trainable params: 8,520\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
