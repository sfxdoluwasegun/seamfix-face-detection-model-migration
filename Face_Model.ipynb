{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D,MaxPooling2D, LeakyReLU, PReLU , Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_tfrecord(tfrecord_file, batch_size, net):\n",
    "    # generate a input queue\n",
    "    # each epoch shuffle\n",
    "    filename_queue = tf.string_input_producer([tfrecord_file],shuffle=True)\n",
    "    # read tfrecord\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    image_features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image/encoded': tf.FixedLenFeature([], tf.string),#one image  one record\n",
    "            'image/label': tf.FixedLenFeature([], tf.int64),\n",
    "            'image/roi': tf.FixedLenFeature([4], tf.float32),\n",
    "            'image/landmark': tf.FixedLenFeature([10],tf.float32)\n",
    "        }\n",
    "    )\n",
    "    if net == 'PNet':\n",
    "        image_size = 12\n",
    "    elif net == 'RNet':\n",
    "        image_size = 24\n",
    "    else:\n",
    "        image_size = 48\n",
    "    image = tf.decode_raw(image_features['image/encoded'], tf.uint8)\n",
    "    image = tf.reshape(image, [image_size, image_size, 3])\n",
    "    image = (tf.cast(image, tf.float32)-127.5) / 128\n",
    "    \n",
    "    # image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(image_features['image/label'], tf.float32)\n",
    "    roi = tf.cast(image_features['image/roi'],tf.float32)\n",
    "    landmark = tf.cast(image_features['image/landmark'],tf.float32)\n",
    "    image, label,roi,landmark = tf.train.batch(\n",
    "        [image, label,roi,landmark],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=2,\n",
    "        capacity=1 * batch_size\n",
    "    )\n",
    "    label = tf.reshape(label, [batch_size])\n",
    "    roi = tf.reshape(roi,[batch_size,4])\n",
    "    landmark = tf.reshape(landmark,[batch_size,10])\n",
    "    return image, label, roi,landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class PNet():\n",
    "    #P-Net\n",
    "\n",
    "\n",
    "    # Data Preprocessing\n",
    "    # before passing your data into a neural network you normalize the data by Scaling it\n",
    "\n",
    "    # scaling the data \n",
    "    #X = X/255.0\n",
    "\n",
    "    #you can also use tf.keras.utils.normalize(X) \n",
    "#     x = layers.Dense(64, activation='relu')(inputs)\n",
    "#     x = layers.Dense(64, activation='relu')(x)\n",
    "#     predictions = layers.Dense(10, activation='softmax')(x)\n",
    "    # Convoluted neural network\n",
    "\n",
    "def p_net():\n",
    "\n",
    "    model = Sequential() #there are 2 types of models but this is the most common\n",
    "    model.add(Conv2D(10,(3, 3), strides=1, name='conv1',padding='SAME', input_shape =(12, 12, 3) ) )\n",
    "    model.add(PReLU(name='prelu1'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(16,(3, 3), strides=1,name='conv2', input_shape =(5, 5, 10)))\n",
    "    model.add(PReLU(name='prelu2'))\n",
    "\n",
    "    model.add(Conv2D(32,(3,3),strides=1,name='conv3'))\n",
    "    model.add(PReLU(name='prelu3'))\n",
    "\n",
    "    model.add(Conv2D(2, (1, 1), activation='softmax',name='classifier1'))\n",
    "    model.add(PReLU(name='prelu4'))\n",
    "\n",
    "    model.add(Dense(4,name='bbox_regression'))\n",
    "\n",
    "    model.add(Dense(10,name='landmark'))\n",
    "\n",
    "    #model = tf.keras.Model(inputs=, outputs=)\n",
    "    model.compile(optimizer=tf.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    #my_adam = adam(lr = 0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#R-Net\n",
    "\n",
    "def r_net():\n",
    "    model = Sequential() #there are 2 types of models but this is the most common\n",
    "    model.add(Conv2D(28, (3, 3), strides=1, name='conv1', input_shape =(24, 24, 3)))\n",
    "    model.add(PReLU(name='prelu1'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(48, (3, 3), strides=1, name='conv2'))\n",
    "    model.add(PReLU(name='prelu2'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (2, 2), strides=1, name='conv3'))\n",
    "    model.add(PReLU(name='prelu3'))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(PReLU(name='prelu4'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.add(Dense(4))#THere is something being used input_layer_name='prelu4)\n",
    "\n",
    "#O-Net\n",
    "\n",
    "def o_net():\n",
    "    model = Sequential() #there are 2 types of models but this is the most common\n",
    "    model.add(Conv2D(32, (3, 3), strides=1, name='conv1'), input_shape =(48, 48, 3))\n",
    "    model.add(PReLU(name='prelu1'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides=1, name='conv2'))\n",
    "    model.add(PReLU(name='prelu2'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides=1, name='conv3'))\n",
    "    model.add(PReLU(name='prelu3'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(128, (2, 2), strides=1, name='conv4'))\n",
    "    model.add(PReLU(name='prelu4'))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(PReLU(name='prelu5'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.add(Dense(4))#THere is something being used input_layer_name='prelu5\n",
    "\n",
    "    model.add(Dense(10))#THere is something being used input_layer_name='prelu5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = PNet\n",
    "# batch_size = 32\n",
    "\n",
    "\n",
    "# def read_single_tfrecord(tfrecord_file, batch_size, net):\n",
    "#     # generate a input queue\n",
    "#     # each epoch shuffle\n",
    "#     filename_queue = tf.string_input_producer([tfrecord_file],shuffle=True)\n",
    "#     # read tfrecord\n",
    "#     reader = tf.TFRecordReader()\n",
    "#     _, serialized_example = reader.read(filename_queue)\n",
    "#     image_features = tf.parse_single_example(\n",
    "#         serialized_example,\n",
    "#         features={\n",
    "#             'image/encoded': tf.FixedLenFeature([], tf.string),#one image  one record\n",
    "#             'image/label': tf.FixedLenFeature([], tf.int64),\n",
    "#             'image/roi': tf.FixedLenFeature([4], tf.float32),\n",
    "#             'image/landmark': tf.FixedLenFeature([10],tf.float32)\n",
    "#         }\n",
    "#     )\n",
    "#     if net == 'PNet':\n",
    "#         image_size = 12\n",
    "#     elif net == 'RNet':\n",
    "#         image_size = 24\n",
    "#     else:\n",
    "#         image_size = 48\n",
    "#     image = tf.decode_raw(image_features['image/encoded'], tf.uint8)\n",
    "#     image = tf.reshape(image, [image_size, image_size, 3])\n",
    "#     image = (tf.cast(image, tf.float32)-127.5) / 128\n",
    "    \n",
    "#     # image = tf.image.per_image_standardization(image)\n",
    "#     label = tf.cast(image_features['image/label'], tf.float32)\n",
    "#     roi = tf.cast(image_features['image/roi'],tf.float32)\n",
    "#     landmark = tf.cast(image_features['image/landmark'],tf.float32)\n",
    "#     image, label,roi,landmark = tf.train.batch(\n",
    "#         [image, label,roi,landmark],\n",
    "#         batch_size=batch_size,\n",
    "#         num_threads=2,\n",
    "#         capacity=1 * batch_size\n",
    "#     )\n",
    "#     label = tf.reshape(label, [batch_size])\n",
    "#     roi = tf.reshape(roi,[batch_size,4])\n",
    "#     landmark = tf.reshape(landmark,[batch_size,10])\n",
    "#     return image, label, roi,landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = p_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 12, 12, 10)        280       \n",
      "_________________________________________________________________\n",
      "prelu1 (PReLU)               (None, 12, 12, 10)        1440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 3, 3, 16)          1456      \n",
      "_________________________________________________________________\n",
      "prelu2 (PReLU)               (None, 3, 3, 16)          144       \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 1, 1, 32)          4640      \n",
      "_________________________________________________________________\n",
      "prelu3 (PReLU)               (None, 1, 1, 32)          32        \n",
      "_________________________________________________________________\n",
      "classifier1 (Conv2D)         (None, 1, 1, 2)           66        \n",
      "_________________________________________________________________\n",
      "prelu4 (PReLU)               (None, 1, 1, 2)           2         \n",
      "_________________________________________________________________\n",
      "bbox_regression (Dense)      (None, 1, 1, 4)           12        \n",
      "_________________________________________________________________\n",
      "landmark (Dense)             (None, 1, 1, 10)          50        \n",
      "=================================================================\n",
      "Total params: 8,122\n",
      "Trainable params: 8,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your own reader function.\n",
    "image_features = tf.parse_single_example(\n",
    "       serialized_example,\n",
    "       features={\n",
    "           'image/encoded': tf.FixedLenFeature([], tf.string),#one image  one record\n",
    "           'image/label': tf.FixedLenFeature([], tf.int64),\n",
    "           'image/roi': tf.FixedLenFeature([4], tf.float32),\n",
    "           'image/landmark': tf.FixedLenFeature([10],tf.float32)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_record(example):\n",
    "    image_features = tf.io.parse_single_example(\n",
    "       example,\n",
    "       features={\n",
    "           'image/encoded': tf.io.FixedLenFeature([], tf.string),#one image  one record\n",
    "           'image/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "           'image/roi': tf.io.FixedLenFeature([4], tf.float32),\n",
    "           'image/landmark': tf.io.FixedLenFeature([10],tf.float32)\n",
    "       }\n",
    "    )\n",
    "    image = tf.io.decode_raw(image_features['image/encoded'], tf.uint8)\n",
    "    image = tf.reshape(image, [12, 12, 3])\n",
    "    image = (tf.cast(image, tf.float32)-127.5) / 128\n",
    "    \n",
    "    # image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(image_features['image/label'], tf.float32)\n",
    "    roi = tf.cast(image_features['image/roi'],tf.float32)\n",
    "    landmark = tf.cast(image_features['image/landmark'],tf.float32)\n",
    "    return image, (label, roi,landmark)\n",
    "        \n",
    "\n",
    "    \n",
    "# image, label,roi,landmark = tf.train.batch(\n",
    "#     [image, label,roi,landmark],\n",
    "#     batch_size=batch_size,\n",
    "#     num_threads=2,\n",
    "#     capacity=1 * batch_size\n",
    "# )\n",
    "# label = tf.reshape(label, [batch_size])\n",
    "# roi = tf.reshape(roi,[batch_size,4])\n",
    "# landmark = tf.reshape(landmark,[batch_size,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 384\n",
    "\n",
    "buffer_size=10 * BATCH_SIZE\n",
    "\n",
    "def get_batch(filenames):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "    \n",
    "    \n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    \n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset)\n",
    "    dataset = dataset.map(read_record)\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    \n",
    "    dataset = dataset.prefetch(buffer_size=buffer_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filename = \"train_PNet_landmark.tfrecord_shuffle\"\n",
    "validation_filename = \"train_PNet_landmark.tfrecord_shuffle\"\n",
    "def get_training_datest():\n",
    "    return get_batch(training_filename)\n",
    "\n",
    "def get_validation_dataset():\n",
    "    return get_batch(validation_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_net():\n",
    "\n",
    "        inputs = tf.keras.Input(shape=(12,12,3))\n",
    "\n",
    "        model = tf.keras.layers.Conv2D(10,(3, 3), strides=1, name='conv1',padding='SAME')(inputs)\n",
    "        model = tf.keras.layers.PReLU(name='prelu1')(model)\n",
    "        model = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2))(model)\n",
    "\n",
    "        model = tf.keras.layers.Conv2D(16,(3, 3), strides=1,name='conv2')(model)\n",
    "        model = tf.keras.layers.PReLU(name='prelu2')(model)\n",
    "\n",
    "        model = tf.keras.layers.Conv2D(32,(3,3),strides=1,name='conv3')(model)\n",
    "        model = tf.keras.layers.PReLU(name='prelu3')(model)\n",
    "\n",
    "        classifier1 = tf.keras.layers.Conv2D(2, (1, 1), activation='softmax',name='classifier1')(model)\n",
    "        #I am not sure if this line of code is impoertant\n",
    "        classifier1 = tf.keras.layers.Reshape((2,))(classifier1)   # this layer has to be deleted in order to enalbe arbitraty shape input\n",
    "\n",
    "        bbox_regress = Conv2D(4, (1, 1),name='bbox1')(model)\n",
    "        #I am not sure if this line of code is impoertant\n",
    "        bbox_regress = tf.keras.layers.Reshape((4,))(bbox_regress)\n",
    "\n",
    "        #THis last code is not usually included in most mtcnn replicas\n",
    "        landmark = Conv2D(10, (1, 1),name='landmark1')(model)\n",
    "        landmark =  tf.keras.layers.Reshape((10,))(landmark)\n",
    "\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=[classifier1,bbox_regress,landmark])\n",
    "        model.compile(optimizer=tf.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsss = p_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /Users/adekunleba/anaconda3/envs/tensorflow20/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "100/100 [==============================] - 6s 59ms/step - loss: -1.9795 - reshape_loss: -3.6012 - reshape_1_loss: 0.1264 - reshape_2_loss: 1.4953 - reshape_accuracy: 0.0065 - reshape_1_accuracy: 0.0530 - reshape_2_accuracy: 0.0458 - val_loss: -2.5176 - val_reshape_loss: -4.0472 - val_reshape_1_loss: 0.1121 - val_reshape_2_loss: 1.4175 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0397 - val_reshape_2_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 4s 38ms/step - loss: -2.5761 - reshape_loss: -4.1282 - reshape_1_loss: 0.1225 - reshape_2_loss: 1.4295 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0403 - reshape_2_accuracy: 0.0038 - val_loss: -2.5279 - val_reshape_loss: -4.0555 - val_reshape_1_loss: 0.1064 - val_reshape_2_loss: 1.4213 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0399 - val_reshape_2_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 4s 36ms/step - loss: -2.5272 - reshape_loss: -4.0635 - reshape_1_loss: 0.1064 - reshape_2_loss: 1.4299 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0406 - reshape_2_accuracy: 0.0337 - val_loss: -2.4922 - val_reshape_loss: -4.0127 - val_reshape_1_loss: 0.1063 - val_reshape_2_loss: 1.4142 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0399 - val_reshape_2_accuracy: 0.0017\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 4s 36ms/step - loss: -2.4520 - reshape_loss: -3.9573 - reshape_1_loss: 0.1225 - reshape_2_loss: 1.3829 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0405 - reshape_2_accuracy: 0.0103 - val_loss: -2.5155 - val_reshape_loss: -4.0497 - val_reshape_1_loss: 0.1123 - val_reshape_2_loss: 1.4219 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0399 - val_reshape_2_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 4s 37ms/step - loss: -2.5018 - reshape_loss: -4.0039 - reshape_1_loss: 0.1056 - reshape_2_loss: 1.3965 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0424 - reshape_2_accuracy: 0.0228 - val_loss: -2.4992 - val_reshape_loss: -4.0404 - val_reshape_1_loss: 0.1121 - val_reshape_2_loss: 1.4291 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0398 - val_reshape_2_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 4s 37ms/step - loss: -2.4193 - reshape_loss: -3.9619 - reshape_1_loss: 0.1378 - reshape_2_loss: 1.4049 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0410 - reshape_2_accuracy: 0.0516 - val_loss: -2.5321 - val_reshape_loss: -4.0656 - val_reshape_1_loss: 0.1108 - val_reshape_2_loss: 1.4227 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0400 - val_reshape_2_accuracy: 5.2083e-05\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 4s 39ms/step - loss: -2.5354 - reshape_loss: -4.0673 - reshape_1_loss: 0.1216 - reshape_2_loss: 1.4103 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0392 - reshape_2_accuracy: 0.0345 - val_loss: -2.5162 - val_reshape_loss: -4.0430 - val_reshape_1_loss: 0.1099 - val_reshape_2_loss: 1.4169 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0402 - val_reshape_2_accuracy: 0.0041\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 4s 40ms/step - loss: -2.5000 - reshape_loss: -4.0283 - reshape_1_loss: 0.1070 - reshape_2_loss: 1.4213 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0405 - reshape_2_accuracy: 0.2044 - val_loss: -2.5325 - val_reshape_loss: -4.0723 - val_reshape_1_loss: 0.1119 - val_reshape_2_loss: 1.4279 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0398 - val_reshape_2_accuracy: 0.3067\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 4s 38ms/step - loss: -2.6155 - reshape_loss: -4.1240 - reshape_1_loss: 0.1016 - reshape_2_loss: 1.4069 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0393 - reshape_2_accuracy: 0.3311 - val_loss: -2.5385 - val_reshape_loss: -4.0514 - val_reshape_1_loss: 0.0844 - val_reshape_2_loss: 1.4284 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0405 - val_reshape_2_accuracy: 0.3011\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 4s 40ms/step - loss: -2.6347 - reshape_loss: -4.1567 - reshape_1_loss: 0.1037 - reshape_2_loss: 1.4183 - reshape_accuracy: 0.0000e+00 - reshape_1_accuracy: 0.0414 - reshape_2_accuracy: 0.4120 - val_loss: -2.5268 - val_reshape_loss: -4.0421 - val_reshape_1_loss: 0.0939 - val_reshape_2_loss: 1.4214 - val_reshape_accuracy: 0.0000e+00 - val_reshape_1_accuracy: 0.0402 - val_reshape_2_accuracy: 0.5705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12d9d5b00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsss.fit(get_training_datest(), steps_per_epoch=100, epochs=10, validation_data=get_validation_dataset(), validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 12, 12, 10)   280         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prelu1 (PReLU)                  (None, 12, 12, 10)   1440        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 5, 5, 10)     0           prelu1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 3, 3, 16)     1456        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prelu2 (PReLU)                  (None, 3, 3, 16)     144         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 1, 1, 32)     4640        prelu2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prelu3 (PReLU)                  (None, 1, 1, 32)     32          conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "classifier1 (Conv2D)            (None, 1, 1, 2)      66          prelu3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bbox1 (Conv2D)                  (None, 1, 1, 4)      132         prelu3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "landmark1 (Conv2D)              (None, 1, 1, 10)     330         prelu3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 2)            0           classifier1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 4)            0           bbox1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10)           0           landmark1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,520\n",
      "Trainable params: 8,520\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
