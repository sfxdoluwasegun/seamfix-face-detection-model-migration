{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D,MaxPooling2D, LeakyReLU, PReLU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_tfrecord(tfrecord_file, batch_size, net):\n",
    "    # generate a input queue\n",
    "    # each epoch shuffle\n",
    "    filename_queue = tf.string_input_producer([tfrecord_file],shuffle=True)\n",
    "    # read tfrecord\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    image_features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image/encoded': tf.FixedLenFeature([], tf.string),#one image  one record\n",
    "            'image/label': tf.FixedLenFeature([], tf.int64),\n",
    "            'image/roi': tf.FixedLenFeature([4], tf.float32),\n",
    "            'image/landmark': tf.FixedLenFeature([10],tf.float32)\n",
    "        }\n",
    "    )\n",
    "    if net == 'PNet':\n",
    "        image_size = 12\n",
    "    elif net == 'RNet':\n",
    "        image_size = 24\n",
    "    else:\n",
    "        image_size = 48\n",
    "    image = tf.decode_raw(image_features['image/encoded'], tf.uint8)\n",
    "    image = tf.reshape(image, [image_size, image_size, 3])\n",
    "    image = (tf.cast(image, tf.float32)-127.5) / 128\n",
    "    \n",
    "    # image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(image_features['image/label'], tf.float32)\n",
    "    roi = tf.cast(image_features['image/roi'],tf.float32)\n",
    "    landmark = tf.cast(image_features['image/landmark'],tf.float32)\n",
    "    image, label,roi,landmark = tf.train.batch(\n",
    "        [image, label,roi,landmark],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=2,\n",
    "        capacity=1 * batch_size\n",
    "    )\n",
    "    label = tf.reshape(label, [batch_size])\n",
    "    roi = tf.reshape(roi,[batch_size,4])\n",
    "    landmark = tf.reshape(landmark,[batch_size,10])\n",
    "    return image, label, roi,landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class PNet():\n",
    "    #P-Net\n",
    "\n",
    "\n",
    "    # Data Preprocessing\n",
    "    # before passing your data into a neural network you normalize the data by Scaling it\n",
    "\n",
    "    # scaling the data \n",
    "    #X = X/255.0\n",
    "\n",
    "    #you can also use tf.keras.utils.normalize(X) \n",
    "    x = layers.Dense(64, activation='relu')(inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    predictions = layers.Dense(10, activation='softmax')(x)\n",
    "    # Convoluted neural network\n",
    "\n",
    "    def p_net():\n",
    "        \n",
    "        model = Sequential() #there are 2 types of models but this is the most common\n",
    "        model.add(Conv2D(10,(3, 3), strides=1, name='conv1',padding='SAME', input_shape =(12, 12, 3) ) )\n",
    "        model.add(PReLU(name='prelu1'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "        model.add(Conv2D(16,(3, 3), strides=1,name='conv2', input_shape =(5, 5, 10)))\n",
    "        model.add(PReLU(name='prelu2'))\n",
    "\n",
    "        model.add(Conv2D(32,(3,3),strides=1,name='conv3'))\n",
    "        model.add(PReLU(name='prelu3'))\n",
    "\n",
    "        model.add(Conv2D(2, (1, 1), activation='softmax',name='classifier1'))\n",
    "        model.add(PReLU(name='prelu4'))\n",
    "\n",
    "        model.add(Dense(4,name='bbox_regression'))\n",
    "\n",
    "        model.add(Dense(10,name='landmark'))\n",
    "        \n",
    "        #model = tf.keras.Model(inputs=, outputs=)\n",
    "        model.compile(optimizer=tf.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        #my_adam = adam(lr = 0.00001)\n",
    "\n",
    "        \n",
    "                         \n",
    "                         \n",
    "    #R-Net\n",
    "\n",
    "    def r_net():\n",
    "        model = Sequential() #there are 2 types of models but this is the most common\n",
    "        model.add(Conv2D(28, (3, 3), strides=1, name='conv1', input_shape =(24, 24, 3)))\n",
    "        model.add(PReLU(name='prelu1'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "        model.add(Conv2D(48, (3, 3), strides=1, name='conv2'))\n",
    "        model.add(PReLU(name='prelu2'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "        model.add(Conv2D(64, (2, 2), strides=1, name='conv3'))\n",
    "        model.add(PReLU(name='prelu3'))\n",
    "\n",
    "        model.add(Dense(128))\n",
    "        model.add(PReLU(name='prelu4'))\n",
    "\n",
    "        model.add(Dense(2))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        model.add(Dense(4))#THere is something being used input_layer_name='prelu4)\n",
    "\n",
    "    #O-Net\n",
    "\n",
    "    def o_net():\n",
    "        model = Sequential() #there are 2 types of models but this is the most common\n",
    "        model.add(Conv2D(32, (3, 3), strides=1, name='conv1'), input_shape =(48, 48, 3))\n",
    "        model.add(PReLU(name='prelu1'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), strides=1, name='conv2'))\n",
    "        model.add(PReLU(name='prelu2'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), strides=1, name='conv3'))\n",
    "        model.add(PReLU(name='prelu3'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "        model.add(Conv2D(128, (2, 2), strides=1, name='conv4'))\n",
    "        model.add(PReLU(name='prelu4'))\n",
    "\n",
    "        model.add(Dense(256))\n",
    "        model.add(PReLU(name='prelu5'))\n",
    "\n",
    "        model.add(Dense(2))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        model.add(Dense(4))#THere is something being used input_layer_name='prelu5\n",
    "\n",
    "        model.add(Dense(10))#THere is something being used input_layer_name='prelu5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_tfrecord(tfrecord_file, batch_size, net):\n",
    "    # generate a input queue\n",
    "    # each epoch shuffle\n",
    "    filename_queue = tf.string_input_producer([tfrecord_file],shuffle=True)\n",
    "    # read tfrecord\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    image_features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image/encoded': tf.FixedLenFeature([], tf.string),#one image  one record\n",
    "            'image/label': tf.FixedLenFeature([], tf.int64),\n",
    "            'image/roi': tf.FixedLenFeature([4], tf.float32),\n",
    "            'image/landmark': tf.FixedLenFeature([10],tf.float32)\n",
    "        }\n",
    "    )\n",
    "    if net == 'PNet':\n",
    "        image_size = 12\n",
    "    elif net == 'RNet':\n",
    "        image_size = 24\n",
    "    else:\n",
    "        image_size = 48\n",
    "    image = tf.decode_raw(image_features['image/encoded'], tf.uint8)\n",
    "    image = tf.reshape(image, [image_size, image_size, 3])\n",
    "    image = (tf.cast(image, tf.float32)-127.5) / 128\n",
    "    \n",
    "    # image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(image_features['image/label'], tf.float32)\n",
    "    roi = tf.cast(image_features['image/roi'],tf.float32)\n",
    "    landmark = tf.cast(image_features['image/landmark'],tf.float32)\n",
    "    image, label,roi,landmark = tf.train.batch(\n",
    "        [image, label,roi,landmark],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=2,\n",
    "        capacity=1 * batch_size\n",
    "    )\n",
    "    label = tf.reshape(label, [batch_size])\n",
    "    roi = tf.reshape(roi,[batch_size,4])\n",
    "    landmark = tf.reshape(landmark,[batch_size,10])\n",
    "    return image, label, roi,landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
